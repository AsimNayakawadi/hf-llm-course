{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e7e1c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598049521446228},\n",
       " {'label': 'NEGATIVE', 'score': 0.9966409206390381}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier([\"I've been waiting for a HuggingFace course my whole life.\",\n",
    "        \"I hate this so much!\",])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3045071f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9765d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 101, 2003, 1996,  102]]), 'attention_mask': tensor([[1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "raw_inputs = [\n",
    "    \"is the\",\n",
    "]\n",
    "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40c80afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## output is a dictionary that contains two keys input_id and attention_mask input_ids contains two rows of integers (one for each sentence) that are the unique identifiers of the tokens in each sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc779b15",
   "metadata": {},
   "source": [
    "101   → [CLS]\n",
    "1045  → I\n",
    "1005  → '\n",
    "2310  → ve\n",
    "2042  → been\n",
    "3403  → waiting\n",
    "2005  → for\n",
    "1037  → a\n",
    "17662 → Hugging\n",
    "12172 → Face\n",
    "2607  → course\n",
    "2026  → my\n",
    "2878  → whole\n",
    "2166  → life\n",
    "1012  → .\n",
    "102   → [SEP]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af165517",
   "metadata": {},
   "source": [
    "Words can be split into subwords (Hugging + Face)\n",
    "\n",
    "Apostrophes are handled as separate tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da9c1e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets download our pretrained model using automodel class which has from_pretrained() method\n",
    "\n",
    "from transformers import AutoModel\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "model = AutoModel.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f739dd9",
   "metadata": {},
   "source": [
    "For each model input, we’ll retrieve a high-dimensional vector representing the contextual understanding of that input by the Transformer model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d64d250",
   "metadata": {},
   "source": [
    "This models head is for this task for different tasks we use different model heads.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b77e61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "outputs = model(**inputs)\n",
    "print(outputs.last_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708e239c",
   "metadata": {},
   "source": [
    "Outputs of transformers models behave like namedtuples or dictionaries.\n",
    "To access them use outputs[\"last_hidden_state\"]\n",
    "or even by index if you know exactly where the thing you are looking for is (outputs[0])."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdea25e1",
   "metadata": {},
   "source": [
    "Lets use a model for sequence classification task i.e. to classify sentences as positive or negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b9e7134",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "output = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b46be1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "print(output.logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "936352e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "print(outputs.last_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99b0d01f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BaseModelOutput' object has no attribute 'logits'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogits\u001b[49m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BaseModelOutput' object has no attribute 'logits'"
     ]
    }
   ],
   "source": [
    "print(outputs.logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "500ca97b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BaseModelOutput' object has no attribute 'logits'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m predictions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogits\u001b[49m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(predictions)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BaseModelOutput' object has no attribute 'logits'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e530fdec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'NEGATIVE', 1: 'POSITIVE'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d057d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
